{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sQl1kl-B7f2",
        "outputId": "d499dc4a-6ef3-49de-cf16-c840c40468a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-03 12:41:50--  https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/data_cleaning.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2377 (2.3K) [text/plain]\n",
            "Saving to: ‘data_cleaning.txt’\n",
            "\n",
            "\rdata_cleaning.txt     0%[                    ]       0  --.-KB/s               \rdata_cleaning.txt   100%[===================>]   2.32K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-03 12:41:50 (31.6 MB/s) - ‘data_cleaning.txt’ saved [2377/2377]\n",
            "\n",
            "<!DOCTYPE html>\n",
            "<html>\n",
            "<head>\n",
            "    <title>Sample HTML Document</title>\n",
            "</head>\n",
            "<body>\n",
            "    <h1>Welcome\n"
          ]
        }
      ],
      "source": [
        "#1\n",
        "# загружаем тренировочные данные\n",
        "!wget https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/data_cleaning.txt\n",
        "# запишем данные в переменную data\n",
        "with open('data_cleaning.txt', 'r') as f:\n",
        "  data = f.read()\n",
        "\n",
        "# выведите на экран первые 100 символов с помощью слайсинга\n",
        "print(data[:100])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2.1 удаляем артефакты\n",
        "import re   # загрузим библиотеку для обработки регулярных выражений\n",
        "\n",
        "tag_pattern = r'<[^>]+>'\n",
        "\n",
        "# Подсказки:\n",
        "# используйте паттерн, записанный в переменную tag_pattern\n",
        "# замените результат на пустую строку \"\"\n",
        "### ваш код здесь: примените re.sub ###\n",
        "### ваш код здесь: выведите результат с 720-го по 800-ый символ ###\n",
        "# Удалим HTML-артефакты с помощью регулярных выражений RegEx\n",
        "\n",
        "tag_pattern = r'<[^>]+>'  # паттерн для поиска тегов\n",
        "clean_text = re.sub(tag_pattern, '', data)\n",
        "\n",
        "# Выведите на экран с 720-го по 800-ый символ очищенного текста\n",
        "print(clean_text[720:800])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9JMFIVtDC1X",
        "outputId": "ac614d58-e994-460e-d375-cb62bf82a0f2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " It's crucial to handle HTML entities such as &lt;div&gt;, &lt;p&gt;, &amp;, etc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2.2\n",
        "# поворяем процедуру со след паттерном\n",
        "symbols_pattern = r'&\\w+;'  # паттерн для поиска специальных символов\n",
        "clean_text = re.sub(symbols_pattern, '', clean_text)\n",
        "print(clean_text[720:800])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-saf0zybDys1",
        "outputId": "59d84427-4ea1-4a84-9a42-c12050e6534c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " It's crucial to handle HTML entities such as div, p, , etc. HTML entities are s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2.3\n",
        "#убираем двойные пробелы\n",
        "space_pattern = r'\\s+'\n",
        "clean_text = re.sub(space_pattern, ' ', clean_text)\n",
        "\n",
        "# Выведите на экран первые 100 символов вашего текущего результата, не используя print\n",
        "clean_text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fY0gxs8kD_xy",
        "outputId": "1451f0c2-d6a5-4d40-dfcb-79462e8dd722"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Sample HTML Document Welcome to Data Cleaning This is a sample paragraph with HTML artifacts such a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3 смена регистра\n",
        "text_lower = clean_text.lower()\n",
        "\n",
        "# 100 символов после смены регистра\n",
        "print(text_lower[-100:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ciq4Pj7NEcGR",
        "outputId": "7d8fc30b-e012-4c26-8010-d758d068c16e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e learning models, making predictions, or generating insights to support decision-making processes. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4.1 удаление стоп-слов\n",
        "\n",
        "!wget https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/stopwords.txt\n",
        "\n",
        "# запишем данные в переменную stopwords\n",
        "with open('stopwords.txt', 'r') as f:\n",
        "  stopwords = f.read().split()\n",
        "#вывод первых 10 стоп слов\n",
        "  print(stopwords[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ubt6yIxXE4Fp",
        "outputId": "26bca90c-fa5f-4950-8c19-5c238270bdab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-03 12:54:54--  https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/stopwords.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 954 [text/plain]\n",
            "Saving to: ‘stopwords.txt’\n",
            "\n",
            "\rstopwords.txt         0%[                    ]       0  --.-KB/s               \rstopwords.txt       100%[===================>]     954  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-03 12:54:54 (46.5 MB/s) - ‘stopwords.txt’ saved [954/954]\n",
            "\n",
            "['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4.2\n",
        "\n",
        "import random\n",
        "random.choice(stopwords)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fkefxcZWF_JO",
        "outputId": "3192f604-8551-486e-e0d2-f56e8b6621ae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yours'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4.2.1\n",
        "\n",
        "\n",
        "randomword=random.choice(stopwords)\n",
        "print(randomword)\n",
        "\n",
        "if randomword in text_lower:\n",
        "    print(f\"Слово '{randomword}' есть в тексте.\")\n",
        "else:\n",
        "    print(f\"Слово '{randomword}' нет в тексте.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x49POJBYHRix",
        "outputId": "3da221db-ec61-4c4f-eec0-3a43278ac91c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "herself\n",
            "Слово 'herself' нет в тексте.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4.2.2\n",
        "# еще раз (видим, что стопслова есть)\n",
        "\n",
        "randomword=random.choice(stopwords)\n",
        "print(randomword)\n",
        "\n",
        "if randomword in text_lower:\n",
        "    print(f\"Слово '{randomword}' есть в тексте.\")\n",
        "else:\n",
        "    print(f\"Слово '{randomword}' нет в тексте.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gBhK47OH66W",
        "outputId": "5991f88c-cdf0-4f24-f9c6-49a49320d6b6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "other\n",
            "Слово 'other' есть в тексте.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1токенизция перед удалением стоп слов из текста\n",
        "#по предложениям\n",
        "sentences = text_lower.split('. ')\n",
        "print(sentences[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gA6wkS6IZPJ",
        "outputId": "9524f631-6d7f-4329-a9bd-816261da8df6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' sample html document welcome to data cleaning this is a sample paragraph with html artifacts such as bold and italic text', 'data cleaning is an essential process in preparing data for analysis', 'it involves various techniques to clean, transform, and preprocess data', 'in data cleaning, it\\'s important to remove stop words like \"the\", \"and\", \"of\", etc', 'stop words are common words that are often filtered out from text data because they do not carry significant meaning', \"here's another paragraph\", 'sometimes text is in uppercase or lowercase', \"it's important to standardize the text case to ensure consistency in the dataset\", 'this can be achieved by converting all text to lowercase or uppercase', \"it's crucial to handle html entities such as div, p, , etc\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5.2\n",
        "# по словам\n",
        "tokens = text_lower.split()\n",
        "print(tokens[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25yC0nEwJCuy",
        "outputId": "5870b81e-49c6-4b81-c6d5-8af363f12b4a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sample', 'html', 'document', 'welcome', 'to', 'data', 'cleaning', 'this', 'is', 'a']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5.3 удаляем наконец стоп слова из токенизированного текста\n",
        "\n",
        "clean_tokens = []\n",
        "\n",
        "for token in tokens:  # итерация по списку токенов tokens\n",
        "  if token not in stopwords:  # проверяем отсутствие токена в списке стоп-слов\n",
        "    clean_tokens.append(token)  # добавляем токен в новый очищенный список токенов, если его нет в стоп-словах\n",
        "\n",
        "print(clean_tokens[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlKCylT9JYGR",
        "outputId": "be033a2f-ac9b-4c5f-cd90-a6b78eb3356d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sample', 'html', 'document', 'welcome', 'data', 'cleaning', 'sample', 'paragraph', 'html', 'artifacts']\n"
          ]
        }
      ]
    }
  ]
}